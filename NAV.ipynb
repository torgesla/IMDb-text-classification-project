{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb movie review classification using Keras \n",
    "## Interview presentation for NAV\n",
    "## By Torgeir Sandnes Laurvik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External packages used:\n",
    "* Numpy for array operations\n",
    "* Tensorflow for importing Keras\n",
    "* Keras for building model and loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "imdb_dataset = imdb.load_data(num_words=10000)\n",
    "train_data, train_labels = imdb_dataset[0]\n",
    "test_data, test_labels = imdb_dataset[1]\n",
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add tags to dictonary\n",
    "<!-- https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {k: (v+3) for k, v in word_index.items()}\n",
    "\n",
    "word_index['<PAD>'] = 0\n",
    "word_index['<START>'] = 1\n",
    "word_index['<UNKNOWN>'] = 2\n",
    "word_index['<UNUSED>'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for key, value in word_index.items()])\n",
    "\n",
    "def decode_review(bitmap):  # Converts our review vector back to text\n",
    "    return ' '.join([reverse_word_index.get(bit,'?') for bit in bitmap])\n",
    "\n",
    "def code_review(text):  # Convert text review to vector\n",
    "    coded_string = np.zeros(256)\n",
    "    for i, word in enumerate(text.split(' ')):\n",
    "        coded_string[i] = word_index[word.lower()]\n",
    "    return coded_string\n",
    "\n",
    "def find_maxlen(reviews): #Find max wordcount of reviews\n",
    "    maxlen = -1\n",
    "    for i,review in enumerate(reviews):\n",
    "        a = len(review)\n",
    "        if(a>maxlen):\n",
    "            maxlen=a\n",
    "            j=i       \n",
    "    return j,maxlen\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1: \n",
      " <START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNKNOWN> is an amazing actor and now the same being director <UNKNOWN> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNKNOWN> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNKNOWN> to the two little boy's that played the <UNKNOWN> of norman and paul they were just brilliant children are often left out of the <UNKNOWN> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all \n",
      "\n",
      "EXAMPLE 2: \n",
      " <START> i am a great fan of david lynch and have everything that he's made on dvd except for hotel room the 2 hour twin peaks movie so when i found out about this i immediately grabbed it and and what is this it's a bunch of <UNKNOWN> drawn black and white cartoons that are loud and foul mouthed and unfunny maybe i don't know what's good but maybe this is just a bunch of crap that was <UNKNOWN> on the public under the name of david lynch to make a few bucks too let me make it clear that i didn't care about the foul language part but had to keep <UNKNOWN> the sound because my neighbors might have all in all this is a highly disappointing release and may well have just been left in the <UNKNOWN> box set as a curiosity i highly recommend you don't spend your money on this 2 out of 10\n"
     ]
    }
   ],
   "source": [
    "ex1 = decode_review(train_data[0])\n",
    "ex2 = decode_review(train_data[100])\n",
    "print('EXAMPLE 1: \\n',ex1,'\\n')\n",
    "print('EXAMPLE 2: \\n',ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero padding for correct array shape to input layer\n",
    "#### I decide maxlen to be 256 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first review:  218\n",
      "Length of second review:  189\n",
      "Length of first review:  256\n",
      "Length of second review:  256\n"
     ]
    }
   ],
   "source": [
    "print('Length of first review: ',len(train_data[0]))\n",
    "print('Length of second review: ',len(train_data[1]))\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index['<PAD>'], padding='post', maxlen=256)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index['<PAD>'], padding='post', maxlen=256)\n",
    "print('Length of first review: ',len(train_data[0]))\n",
    "print('Length of second review: ',len(train_data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from dataset after zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1: \n",
      " <START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNKNOWN> is an amazing actor and now the same being director <UNKNOWN> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNKNOWN> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNKNOWN> to the two little boy's that played the <UNKNOWN> of norman and paul they were just brilliant children are often left out of the <UNKNOWN> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "EXAMPLE 2: \n",
      " <START> i am a great fan of david lynch and have everything that he's made on dvd except for hotel room the 2 hour twin peaks movie so when i found out about this i immediately grabbed it and and what is this it's a bunch of <UNKNOWN> drawn black and white cartoons that are loud and foul mouthed and unfunny maybe i don't know what's good but maybe this is just a bunch of crap that was <UNKNOWN> on the public under the name of david lynch to make a few bucks too let me make it clear that i didn't care about the foul language part but had to keep <UNKNOWN> the sound because my neighbors might have all in all this is a highly disappointing release and may well have just been left in the <UNKNOWN> box set as a curiosity i highly recommend you don't spend your money on this 2 out of 10 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "ex1 = decode_review(train_data[0])\n",
    "ex2 = decode_review(train_data[100])\n",
    "print('EXAMPLE 1: \\n',ex1,'\\n')\n",
    "print('EXAMPLE 2: \\n',ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[10000:]\n",
    "x_valid = train_data[:10000]\n",
    "\n",
    "y_train = train_labels[10000:]\n",
    "y_valid = train_labels[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building neural network by adding layers\n",
    "<!-- https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\t. laurvik\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "model = keras.Sequential()\n",
    "\n",
    "embedding = keras.layers.Embedding(vocab_size, 16)  # Group similar words, based on context decreases the angle between vectors.\n",
    "model.add(embedding)\n",
    "\n",
    "globalAverage = keras.layers.GlobalAveragePooling1D()\n",
    "model.add(globalAverage)\n",
    "\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU activation function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/relu.png' width=400 height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid activation function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/sigmoid.png' width=400 height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation phase\n",
    "#### In this phase I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\t. laurvik\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_valid, y_valid), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 24us/sample - loss: 0.3364 - acc: 0.8717\n",
      "Validation loss: 0.336444063706398\n",
      "Validation accuracy: 0.871720016002655\n"
     ]
    }
   ],
   "source": [
    "# Testing phase\n",
    "result = model.evaluate(test_data, test_labels)\n",
    "print(f'Test loss: {result[0]}\\nTest accuracy: {result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting my self written review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My review got predicted to [[0.74220806]]=> closer to 1 than 0 => positive\n"
     ]
    }
   ],
   "source": [
    "# Prediction of my review\n",
    "my_review = 'this movie was really great i liked the ending but the start was not good when i first saw this movie i thought it would be a horrible movie but it ended up being a good experience'\n",
    "coded_review = code_review(my_review)\n",
    "array_form = np.array([coded_review, ])\n",
    "print(f'My review got predicted to {model.predict(array_form)}=> closer to 1 than 0 => positive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
